Module(body=[ImportFrom(module='__future__', names=[alias(name='annotations')], level=0), ImportFrom(module='core', names=[alias(name='Encoding')], level=1), ImportFrom(module='registry', names=[alias(name='get_encoding')], level=1), AnnAssign(target=Name(id='MODEL_PREFIX_TO_ENCODING', ctx=Store()), annotation=Subscript(value=Name(id='dict', ctx=Load()), slice=Tuple(elts=[Name(id='str', ctx=Load()), Name(id='str', ctx=Load())], ctx=Load()), ctx=Load()), value=Dict(keys=[Constant(value='gpt-4-'), Constant(value='gpt-3.5-turbo-'), Constant(value='gpt-35-turbo-'), Constant(value='ft:gpt-4'), Constant(value='ft:gpt-3.5-turbo'), Constant(value='ft:davinci-002'), Constant(value='ft:babbage-002')], values=[Constant(value='cl100k_base'), Constant(value='cl100k_base'), Constant(value='cl100k_base'), Constant(value='cl100k_base'), Constant(value='cl100k_base'), Constant(value='cl100k_base'), Constant(value='cl100k_base')]), simple=1), AnnAssign(target=Name(id='MODEL_TO_ENCODING', ctx=Store()), annotation=Subscript(value=Name(id='dict', ctx=Load()), slice=Tuple(elts=[Name(id='str', ctx=Load()), Name(id='str', ctx=Load())], ctx=Load()), ctx=Load()), value=Dict(keys=[Constant(value='gpt-4'), Constant(value='gpt-3.5-turbo'), Constant(value='gpt-35-turbo'), Constant(value='davinci-002'), Constant(value='babbage-002'), Constant(value='text-embedding-ada-002'), Constant(value='text-davinci-003'), Constant(value='text-davinci-002'), Constant(value='text-davinci-001'), Constant(value='text-curie-001'), Constant(value='text-babbage-001'), Constant(value='text-ada-001'), Constant(value='davinci'), Constant(value='curie'), Constant(value='babbage'), Constant(value='ada'), Constant(value='code-davinci-002'), Constant(value='code-davinci-001'), Constant(value='code-cushman-002'), Constant(value='code-cushman-001'), Constant(value='davinci-codex'), Constant(value='cushman-codex'), Constant(value='text-davinci-edit-001'), Constant(value='code-davinci-edit-001'), Constant(value='text-similarity-davinci-001'), Constant(value='text-similarity-curie-001'), Constant(value='text-similarity-babbage-001'), Constant(value='text-similarity-ada-001'), Constant(value='text-search-davinci-doc-001'), Constant(value='text-search-curie-doc-001'), Constant(value='text-search-babbage-doc-001'), Constant(value='text-search-ada-doc-001'), Constant(value='code-search-babbage-code-001'), Constant(value='code-search-ada-code-001'), Constant(value='gpt2')], values=[Constant(value='cl100k_base'), Constant(value='cl100k_base'), Constant(value='cl100k_base'), Constant(value='cl100k_base'), Constant(value='cl100k_base'), Constant(value='cl100k_base'), Constant(value='p50k_base'), Constant(value='p50k_base'), Constant(value='r50k_base'), Constant(value='r50k_base'), Constant(value='r50k_base'), Constant(value='r50k_base'), Constant(value='r50k_base'), Constant(value='r50k_base'), Constant(value='r50k_base'), Constant(value='r50k_base'), Constant(value='p50k_base'), Constant(value='p50k_base'), Constant(value='p50k_base'), Constant(value='p50k_base'), Constant(value='p50k_base'), Constant(value='p50k_base'), Constant(value='p50k_edit'), Constant(value='p50k_edit'), Constant(value='r50k_base'), Constant(value='r50k_base'), Constant(value='r50k_base'), Constant(value='r50k_base'), Constant(value='r50k_base'), Constant(value='r50k_base'), Constant(value='r50k_base'), Constant(value='r50k_base'), Constant(value='r50k_base'), Constant(value='r50k_base'), Constant(value='gpt2')]), simple=1), FunctionDef(name='encoding_name_for_model', args=arguments(posonlyargs=[], args=[arg(arg='model_name', annotation=Name(id='str', ctx=Load()))], kwonlyargs=[], kw_defaults=[], defaults=[]), body=[Expr(value=Constant(value='Returns the name of the encoding used by a model.\n\n    Raises a KeyError if the model name is not recognised.\n    ')), Assign(targets=[Name(id='encoding_name', ctx=Store())], value=Constant(value=None)), If(test=Compare(left=Name(id='model_name', ctx=Load()), ops=[In()], comparators=[Name(id='MODEL_TO_ENCODING', ctx=Load())]), body=[Assign(targets=[Name(id='encoding_name', ctx=Store())], value=Subscript(value=Name(id='MODEL_TO_ENCODING', ctx=Load()), slice=Name(id='model_name', ctx=Load()), ctx=Load()))], orelse=[For(target=Tuple(elts=[Name(id='model_prefix', ctx=Store()), Name(id='model_encoding_name', ctx=Store())], ctx=Store()), iter=Call(func=Attribute(value=Name(id='MODEL_PREFIX_TO_ENCODING', ctx=Load()), attr='items', ctx=Load()), args=[], keywords=[]), body=[If(test=Call(func=Attribute(value=Name(id='model_name', ctx=Load()), attr='startswith', ctx=Load()), args=[Name(id='model_prefix', ctx=Load())], keywords=[]), body=[Return(value=Name(id='model_encoding_name', ctx=Load()))], orelse=[])], orelse=[])]), If(test=Compare(left=Name(id='encoding_name', ctx=Load()), ops=[Is()], comparators=[Constant(value=None)]), body=[Raise(exc=Call(func=Name(id='KeyError', ctx=Load()), args=[JoinedStr(values=[Constant(value='Could not automatically map '), FormattedValue(value=Name(id='model_name', ctx=Load()), conversion=-1), Constant(value=' to a tokeniser. Please use `tiktoken.get_encoding` to explicitly get the tokeniser you expect.')])], keywords=[]), cause=Constant(value=None))], orelse=[]), Return(value=Name(id='encoding_name', ctx=Load()))], decorator_list=[], returns=Name(id='str', ctx=Load())), FunctionDef(name='encoding_for_model', args=arguments(posonlyargs=[], args=[arg(arg='model_name', annotation=Name(id='str', ctx=Load()))], kwonlyargs=[], kw_defaults=[], defaults=[]), body=[Expr(value=Constant(value='Returns the encoding used by a model.\n\n    Raises a KeyError if the model name is not recognised.\n    ')), Return(value=Call(func=Name(id='get_encoding', ctx=Load()), args=[Call(func=Name(id='encoding_name_for_model', ctx=Load()), args=[Name(id='model_name', ctx=Load())], keywords=[])], keywords=[]))], decorator_list=[], returns=Name(id='Encoding', ctx=Load()))], type_ignores=[])